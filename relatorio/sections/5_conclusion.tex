{\color{gray}\hrule}
\begin{center}
\section{Conclusão}
\end{center}
{\color{gray}\hrule}
\vspace{0.5cm}
O desempenho dos dois classificadores é muito próximo, demonstrando que para o dataset Iris, o KNN é uma alternativa viável à Rede Neural.
Provavelmente seja por questão do tamanho do dataset e quantidade de características.

Essa simplicidade do dataset, faz uma Rede Neural, com tensores, treinamento em GPU, etc. ser um overkill. A dificuldade da implementação supera muito o ganho marginal de desempenho.

O meu foco no experimento foi aprender a utilizar o PyTorch para classificação, pois só possuia experiência com o TensorFlow. Infelizmente a implementação em GPU não foi um sucesso e acabei perdendo tempo demais nisso.
Novamente, o foco estava no aprendizado pois o treinamento em CPU já é muito rápido. Meu ambiente utilizando WSL2 e bypass de GPU para o treinamento não é o ideal.

Apesar desses desafios, o experimento provou ser um exercício valioso de aprendizado.
Aprendi que, embora as Redes Neurais possam ser poderosas ferramentas de aprendizado de máquina, elas não são sempre a melhor ou mais eficiente escolha, 
especialmente para conjuntos de dados menores e mais simples. Ao mesmo tempo, ganhei experiência valiosa com o PyTorch, que certamente será útil para futuros projetos de aprendizado de máquina mais complexos.